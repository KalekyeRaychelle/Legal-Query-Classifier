{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceType":"datasetVersion","sourceId":13372554,"datasetId":8483877,"databundleVersionId":14081178},{"sourceType":"datasetVersion","sourceId":13348676,"datasetId":8465564,"databundleVersionId":14055126}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-13T16:35:09.556124Z","iopub.execute_input":"2025-10-13T16:35:09.556281Z","iopub.status.idle":"2025-10-13T16:35:11.458076Z","shell.execute_reply.started":"2025-10-13T16:35:09.556266Z","shell.execute_reply":"2025-10-13T16:35:11.457371Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/legal-queries/allQuestions.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"pip install -q transformers datasets accelerate scikit-learn numpy pandas\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T16:35:11.459674Z","iopub.execute_input":"2025-10-13T16:35:11.460355Z","iopub.status.idle":"2025-10-13T16:36:38.057412Z","shell.execute_reply.started":"2025-10-13T16:35:11.460333Z","shell.execute_reply":"2025-10-13T16:36:38.056629Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m564.3/564.3 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\npylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\ncudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\nbigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\ncudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\npandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os, json, random\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import classification_report, accuracy_score, f1_score, precision_recall_fscore_support\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, get_linear_schedule_with_warmup, DataCollatorWithPadding\nfrom torch.optim import AdamW","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T17:00:23.246347Z","iopub.execute_input":"2025-10-13T17:00:23.246881Z","iopub.status.idle":"2025-10-13T17:00:23.251991Z","shell.execute_reply.started":"2025-10-13T17:00:23.246855Z","shell.execute_reply":"2025-10-13T17:00:23.251453Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"## COMBINING CV SETS","metadata":{}},{"cell_type":"code","source":"csv_path = \"/kaggle/input/legal-queries/allQuestions.csv\"  \ntext_col = \"question\"\nlabel_col = \"act\"\nmodel_names = [\"roberta-base\", \"distilroberta-base\", \"nlpaueb/legal-bert-base-uncased\"]  # tries in order\nmax_len = 256\ntest_size = 0.2\nseed = 42\nepochs = 4\nbatch_size = 16\nlr = 2e-5\nweight_decay = 0.01\nwarmup_ratio = 0.1\nout_dir = \"/kaggle/working/robertaActsCls\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T17:02:34.113570Z","iopub.execute_input":"2025-10-13T17:02:34.114256Z","iopub.status.idle":"2025-10-13T17:02:34.118233Z","shell.execute_reply.started":"2025-10-13T17:02:34.114235Z","shell.execute_reply":"2025-10-13T17:02:34.117458Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# ====== SEED & DEVICE ======\nrandom.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\nif torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# ====== LOAD DATA ======\ndf = pd.read_csv(csv_path, encoding=\"utf-8-sig\").dropna(subset=[text_col, label_col])\ndf[text_col] = df[text_col].astype(str).str.strip()\ndf[label_col] = df[label_col].astype(str).str.strip()\n\n# ====== ENCODE LABELS & SPLIT ======\nle = LabelEncoder()\ndf[\"label_id\"] = le.fit_transform(df[label_col])\nid2label = {i: lab for i, lab in enumerate(le.classes_)}\nlabel2id = {v: k for k, v in id2label.items()}\nnum_labels = len(id2label)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T17:02:37.500123Z","iopub.execute_input":"2025-10-13T17:02:37.500852Z","iopub.status.idle":"2025-10-13T17:02:37.557768Z","shell.execute_reply.started":"2025-10-13T17:02:37.500825Z","shell.execute_reply":"2025-10-13T17:02:37.557174Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"train_df, test_df = train_test_split(\n    df, test_size=test_size, random_state=seed, stratify=df[\"label_id\"]\n)\n\nprint(f\"Train {len(train_df)} | Test {len(test_df)} | Classes {num_labels}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T17:02:40.997111Z","iopub.execute_input":"2025-10-13T17:02:40.997384Z","iopub.status.idle":"2025-10-13T17:02:41.007174Z","shell.execute_reply.started":"2025-10-13T17:02:40.997364Z","shell.execute_reply":"2025-10-13T17:02:41.006354Z"}},"outputs":[{"name":"stdout","text":"Train 3727 | Test 932 | Classes 20\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"tok = None; model = None; chosen_model = None\nlast_err = None\nfor name in model_names:\n    try:\n        tok = AutoTokenizer.from_pretrained(name, use_fast=True)\n        model = AutoModelForSequenceClassification.from_pretrained(\n            name, num_labels=num_labels, label2id=label2id, id2label=id2label\n        )\n        chosen_model = name\n        break\n    except Exception as e:\n        last_err = e\nif model is None:\n    raise RuntimeError(f\"Could not load any model from {model_names}. Last error: {last_err}\")\n\nprint(\"Using model:\", chosen_model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T17:02:45.777675Z","iopub.execute_input":"2025-10-13T17:02:45.777938Z","iopub.status.idle":"2025-10-13T17:02:50.936691Z","shell.execute_reply.started":"2025-10-13T17:02:45.777918Z","shell.execute_reply":"2025-10-13T17:02:50.935897Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0fff2d41c9fc4e92a41a6136ae9b5439"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d1d4bd86ce44b41af46bf5b2b1a9f58"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cba58d247a464f88aa940fdf1927951c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36751d2c0dbc442db318047468148640"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"720271e8dbbd42e29dfddeb30f0c4cdf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1bda0dab92ac4fb193704ce6b7e98953"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Using model: roberta-base\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"class TxtCls(Dataset):\n    def __init__(self, texts, labels):\n        self.texts = list(texts)\n        self.labels = list(labels)\n    def __len__(self):\n        return len(self.texts)\n    def __getitem__(self, i):\n        return {\"text\": self.texts[i], \"labels\": int(self.labels[i])}\n\ncollator = DataCollatorWithPadding(tokenizer=tok)\n\ndef collate_fn(batch):\n    texts = [b[\"text\"] for b in batch]\n    labels = torch.tensor([b[\"labels\"] for b in batch], dtype=torch.long)\n    enc = tok(texts, truncation=True, max_length=max_len, padding=True, return_tensors=\"pt\")\n    enc[\"labels\"] = labels\n    return enc\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T17:02:56.816695Z","iopub.execute_input":"2025-10-13T17:02:56.817366Z","iopub.status.idle":"2025-10-13T17:02:56.824742Z","shell.execute_reply.started":"2025-10-13T17:02:56.817334Z","shell.execute_reply":"2025-10-13T17:02:56.823911Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"train_ds = TxtCls(train_df[text_col].values, train_df[\"label_id\"].values)\ntest_ds  = TxtCls(test_df[text_col].values,  test_df[\"label_id\"].values)\n\ntrain_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\ntest_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n\n# ====== OPTIM, SCHED ======\nmodel.to(device)\noptim = AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\ntotal_steps = len(train_loader) * epochs\nwarmup_steps = int(total_steps * warmup_ratio)\nsched = get_linear_schedule_with_warmup(optim, num_warmup_steps=warmup_steps, num_training_steps=total_steps)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T17:02:59.530079Z","iopub.execute_input":"2025-10-13T17:02:59.530347Z","iopub.status.idle":"2025-10-13T17:02:59.910944Z","shell.execute_reply.started":"2025-10-13T17:02:59.530328Z","shell.execute_reply":"2025-10-13T17:02:59.910196Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"def evaluate():\n    model.eval()\n    all_true, all_pred = [], []\n    loss_sum, n = 0.0, 0\n    with torch.no_grad():\n        for batch in test_loader:\n            batch = {k: v.to(device) for k, v in batch.items()}\n            out = model(**batch)\n            loss = out.loss\n            logits = out.logits\n            preds = logits.argmax(dim=-1).detach().cpu().numpy().tolist()\n            true  = batch[\"labels\"].detach().cpu().numpy().tolist()\n            all_true += true\n            all_pred += preds\n            loss_sum += float(loss.item()) * len(true)\n            n += len(true)\n    acc = accuracy_score(all_true, all_pred)\n    f1_macro = f1_score(all_true, all_pred, average=\"macro\", zero_division=0)\n    f1_weighted = f1_score(all_true, all_pred, average=\"weighted\", zero_division=0)\n    return {\"loss\": loss_sum / max(n,1), \"accuracy\": acc, \"f1_macro\": f1_macro, \"f1_weighted\": f1_weighted}, all_true, all_pred\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T17:03:04.441776Z","iopub.execute_input":"2025-10-13T17:03:04.442381Z","iopub.status.idle":"2025-10-13T17:03:04.448578Z","shell.execute_reply.started":"2025-10-13T17:03:04.442355Z","shell.execute_reply":"2025-10-13T17:03:04.447666Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"best_f1 = -1.0\nfor ep in range(1, epochs + 1):\n    model.train()\n    running = 0.0\n    for step, batch in enumerate(train_loader, 1):\n        batch = {k: v.to(device) for k, v in batch.items()}\n        out = model(**batch)\n        loss = out.loss\n        loss.backward()\n        optim.step()\n        sched.step()\n        optim.zero_grad()\n        running += float(loss.item())\n        if step % 100 == 0:\n            print(f\"epoch {ep} step {step}/{len(train_loader)} train_loss {running/step:.4f}\")\n\n    train_loss = running / max(1, len(train_loader))\n    metrics, y_true, y_pred = evaluate()\n    val_loss = metrics[\"loss\"]\n    print(f\"epoch {ep} | train_loss {train_loss:.4f} | val_loss {val_loss:.4f} | acc {metrics['accuracy']:.4f} | f1_macro {metrics['f1_macro']:.4f} | f1_weighted {metrics['f1_weighted']:.4f}\")\n\n    if metrics[\"f1_macro\"] > best_f1:\n        best_f1 = metrics[\"f1_macro\"]\n        os.makedirs(out_dir, exist_ok=True)\n        model.save_pretrained(out_dir)\n        tok.save_pretrained(out_dir)\n        with open(os.path.join(out_dir, \"id2label.json\"), \"w\", encoding=\"utf-8\") as f:\n            json.dump(id2label, f, ensure_ascii=False, indent=2)\n        print(\"saved best to\", out_dir)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T17:08:33.908671Z","iopub.execute_input":"2025-10-13T17:08:33.909196Z","iopub.status.idle":"2025-10-13T17:17:11.662625Z","shell.execute_reply.started":"2025-10-13T17:08:33.909170Z","shell.execute_reply":"2025-10-13T17:17:11.661780Z"}},"outputs":[{"name":"stdout","text":"epoch 1 step 100/233 train_loss 1.2364\nepoch 1 step 200/233 train_loss 1.1880\nepoch 1 | train_loss 1.1610 | val_loss 0.9810 | acc 0.7339 | f1_macro 0.6266 | f1_weighted 0.7254\nsaved best to /kaggle/working/robertaActsCls\nepoch 2 step 100/233 train_loss 0.8325\nepoch 2 step 200/233 train_loss 0.8174\nepoch 2 | train_loss 0.8129 | val_loss 0.9053 | acc 0.7543 | f1_macro 0.6441 | f1_weighted 0.7496\nsaved best to /kaggle/working/robertaActsCls\nepoch 3 step 100/233 train_loss 0.6585\nepoch 3 step 200/233 train_loss 0.6275\nepoch 3 | train_loss 0.6271 | val_loss 0.8708 | acc 0.7650 | f1_macro 0.6509 | f1_weighted 0.7593\nsaved best to /kaggle/working/robertaActsCls\nepoch 4 step 100/233 train_loss 0.5601\nepoch 4 step 200/233 train_loss 0.5611\nepoch 4 | train_loss 0.5576 | val_loss 0.8693 | acc 0.7672 | f1_macro 0.6562 | f1_weighted 0.7620\nsaved best to /kaggle/working/robertaActsCls\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"\nmetrics, y_true, y_pred = evaluate()\nprint(\"\\nOverall:\", metrics)\nprint(\"\\nReport:\\n\", classification_report(\n    y_true, y_pred, target_names=[id2label[i] for i in range(num_labels)], digits=4, zero_division=0\n))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T17:17:11.663809Z","iopub.execute_input":"2025-10-13T17:17:11.664070Z","iopub.status.idle":"2025-10-13T17:17:20.699835Z","shell.execute_reply.started":"2025-10-13T17:17:11.664053Z","shell.execute_reply":"2025-10-13T17:17:20.699034Z"}},"outputs":[{"name":"stdout","text":"\nOverall: {'loss': 0.8692839329846427, 'accuracy': 0.7671673819742489, 'f1_macro': 0.6561756629924154, 'f1_weighted': 0.7619751849874999}\n\nReport:\n                                precision    recall  f1-score   support\n\n                 Children Act     0.7458    0.8381    0.7892       105\n        Constitution of Kenya     0.8529    0.8878    0.8700        98\n      Criminal Procedure Code     0.8222    0.8952    0.8571       124\n          Data Protection Act     0.9444    0.7391    0.8293        23\n        Distress for Rent Act     0.8750    0.7000    0.7778        10\n               Employment Act     0.6176    0.5676    0.5915        37\n                 Evidence Act     0.7111    0.6275    0.6667        51\n              Excise Duty Act     0.6923    0.6429    0.6667        28\n          Fatal Accidents Act     0.0000    0.0000    0.0000         3\n               Income Tax Act     0.7350    0.8269    0.7783       104\n         Labour Relations Act     0.7742    0.8000    0.7869        30\n                     Land Act     0.8889    0.8205    0.8533        78\n          Law of Contract Act     0.0000    0.0000    0.0000         2\n        Law of Succession Act     0.8718    0.7234    0.7907        47\n                 Marriage Act     0.7692    0.8333    0.8000        24\nPersons with Disabilities Act     0.7333    0.6667    0.6984        33\n       Small Claims Court Act     0.6667    0.5333    0.5926        15\n           Tax Procedures Act     0.7302    0.8519    0.7863        54\n          Value Added Tax Act     0.5152    0.4474    0.4789        38\n     Work Injury Benefits Act     0.5652    0.4643    0.5098        28\n\n                     accuracy                         0.7672       932\n                    macro avg     0.6756    0.6433    0.6562       932\n                 weighted avg     0.7621    0.7672    0.7620       932\n\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_recall_fscore_support\n\n# class-weighted CE\ncounts = train_df[\"label_id\"].value_counts().sort_index().values\nweights = (len(train_df) / (len(counts) * counts))\nweights = torch.tensor(weights, dtype=torch.float).to(device)\ncriterion = torch.nn.CrossEntropyLoss(weight=weights)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T17:37:26.540652Z","iopub.execute_input":"2025-10-13T17:37:26.541175Z","iopub.status.idle":"2025-10-13T17:37:26.548180Z","shell.execute_reply.started":"2025-10-13T17:37:26.541153Z","shell.execute_reply":"2025-10-13T17:37:26.547448Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"\ndef evaluate():\n    model.eval()\n    all_true, all_pred = [], []\n    loss_sum, n = 0.0, 0\n    with torch.no_grad():\n        for batch in test_loader:\n            batch = {k: v.to(device) for k, v in batch.items()}\n            out = model(**{k: batch[k] for k in [\"input_ids\",\"attention_mask\"]})\n            logits = out.logits\n            loss = criterion(logits, batch[\"labels\"])\n            preds = logits.argmax(dim=-1).detach().cpu().numpy().tolist()\n            true  = batch[\"labels\"].detach().cpu().numpy().tolist()\n            all_true += true\n            all_pred += preds\n            loss_sum += float(loss.item()) * len(true)\n            n += len(true)\n    acc = accuracy_score(all_true, all_pred)\n    f1_macro = f1_score(all_true, all_pred, average=\"macro\", zero_division=0)\n    f1_weighted = f1_score(all_true, all_pred, average=\"weighted\", zero_division=0)\n    return {\"loss\": loss_sum / max(n,1), \"accuracy\": acc, \"f1_macro\": f1_macro, \"f1_weighted\": f1_weighted}, all_true, all_pred\n\nbest_f1 = -1.0\nbad_epochs = 0\npatience = 2\nout_dir1 =\"/kaggle/working/roberaActsCls\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T17:37:29.181433Z","iopub.execute_input":"2025-10-13T17:37:29.181724Z","iopub.status.idle":"2025-10-13T17:37:29.188359Z","shell.execute_reply.started":"2025-10-13T17:37:29.181705Z","shell.execute_reply":"2025-10-13T17:37:29.187735Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"for ep in range(1, epochs + 1):\n    model.train()\n    running = 0.0\n    for step, batch in enumerate(train_loader, 1):\n        batch = {k: v.to(device) for k, v in batch.items()}\n        out = model(**{k: batch[k] for k in [\"input_ids\",\"attention_mask\"]})\n        logits = out.logits\n        loss = criterion(logits, batch[\"labels\"])\n        loss.backward()\n        optim.step()\n        sched.step()\n        optim.zero_grad()\n        running += float(loss.item())\n        if step % 100 == 0:\n            print(f\"epoch {ep} step {step}/{len(train_loader)} train_loss {running/step:.4f}\")\n\n    train_loss = running / max(1, len(train_loader))\n    metrics, y_true, y_pred = evaluate()\n    val_loss = metrics[\"loss\"]\n    print(f\"epoch {ep} | train_loss {train_loss:.4f} | val_loss {val_loss:.4f} | acc {metrics['accuracy']:.4f} | f1_macro {metrics['f1_macro']:.4f} | f1_weighted {metrics['f1_weighted']:.4f}\")\n\n    if metrics[\"f1_macro\"] > best_f1 + 1e-4:\n        best_f1 = metrics[\"f1_macro\"]\n        bad_epochs = 0\n        os.makedirs(out_dir, exist_ok=True)\n        model.save_pretrained(out_dir)\n        tok.save_pretrained(out_dir)\n        with open(os.path.join(out_dir, \"id2label.json\"), \"w\", encoding=\"utf-8\") as f:\n            json.dump(id2label, f, ensure_ascii=False, indent=2)\n        print(\"saved best to\", out_dir)\n    else:\n        bad_epochs += 1\n        if bad_epochs >= patience:\n            print(\"early stop\")\n            break\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T17:37:31.708835Z","iopub.execute_input":"2025-10-13T17:37:31.709117Z","execution_failed":"2025-10-13T19:11:07.038Z"}},"outputs":[{"name":"stdout","text":"epoch 1 step 100/233 train_loss 0.7590\nepoch 1 step 200/233 train_loss 0.8463\nepoch 1 | train_loss 0.8523 | val_loss 1.2549 | acc 0.7672 | f1_macro 0.6562 | f1_weighted 0.7620\nsaved best to /kaggle/working/robertaActsCls\nepoch 2 step 100/233 train_loss 0.8322\nepoch 2 step 200/233 train_loss 0.8330\nepoch 2 | train_loss 0.8443 | val_loss 1.2549 | acc 0.7672 | f1_macro 0.6562 | f1_weighted 0.7620\nepoch 3 step 100/233 train_loss 0.9158\nepoch 3 step 200/233 train_loss 0.8593\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"metrics, y_true, y_pred = evaluate()\nprint(\"\\nOverall:\", metrics)\nprint(\"\\nReport:\\n\", classification_report(\n    y_true, y_pred, target_names=[id2label[i] for i in range(num_labels)], digits=4, zero_division=0\n))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T19:12:01.166789Z","iopub.execute_input":"2025-10-13T19:12:01.167141Z","iopub.status.idle":"2025-10-13T19:12:01.246004Z","shell.execute_reply.started":"2025-10-13T19:12:01.167123Z","shell.execute_reply":"2025-10-13T19:12:01.244954Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_37/2179077338.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nOverall:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m print(\"\\nReport:\\n\", classification_report(\n\u001b[1;32m      4\u001b[0m     \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid2label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdigits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzero_division\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m ))\n","\u001b[0;31mNameError\u001b[0m: name 'evaluate' is not defined"],"ename":"NameError","evalue":"name 'evaluate' is not defined","output_type":"error"}],"execution_count":1},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}